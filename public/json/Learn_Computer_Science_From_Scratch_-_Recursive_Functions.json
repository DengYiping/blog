{"date": "2018-08-05 21:13", "md": "Recursive functions are amazing tools for programmers to do iteration without using a traditional for-loop. It is also the only tool in function programming language to do iteration.\n\nIn Haskell, recursive functions look like this:\n\n```Haskell\n\n    sum_up x\n      ' x == 0 = 0\n      ' otherwise = x + sum_up (x - 1)\n\n```\nThis is a recursive functions that returns the sum of natural numbers from 0 to n in just three line of code. Amazing right?\n\nBut, sometimes, recursive functions are hard to understand, so we need to formulate a way to comprehend the algorithm and check if the algorithm is working.\n\n**To prove a recursive algorithm is working, we need to prove three idea of this algorithm**:\n\n*   **Initialization**: Checking the boundary of inputs, make sure the variable is properly initialized.\n*   **Maintenance**: the assumption for the algorithm holds before and after every recursive calls\n*   **Termination**: we do not want a recursive algorithm that never terminates( infinite recursive calls will consumes large amount of memory.)\nIf you read through my code for sum up again, you will see that it is not properly initialized. What if I gave a negative number as an input? We need to code defensively to make a more robust program. (Such idea is called defensive programming)\n\nTo understand better for recursive algorithm, I will give you a example of Fibonacci function, which calculates the nth number in a Fibonacci sequence.\n\n```Haskell\n\n    fib :: Integer -> Integer\n    fib x\n      ' x < 1 = error \"n should be greater than 0\" \n      ' x == 1 = 1\n      ' x == 2 = 2\n      ' otherwise = fib (x - 1) + fib (x - 2)\n\n```\n**Note** that this is just a simple version, and it is not the optimal algorithm for calculating Fibonacci number.(the time complexity is exponential, and there is a solution to reduce this algorithm to linear time, think about it.)", "title": "Learn Computer Science From Scratch - Recursive Functions"}