{"Learn_Computer_Science_From_Scratch_--_Map_and_Reduce_in_Function_world": {"date": "2018-08-05 21:13", "md": "In functional world, there is C-style for and while loop, and everything is based on recursion. However, sometimes, recursive algorithms can leads to problems in efficiency and readability.</span>\r\n\r\nIn may functional programming language, and in the world of Big Data processing, we use a technique called MapReduce.\r\n\r\nIn map function,  the **first** argument of map function is a functor( you can think of it as a function)  that is defined on every element of the lists, and map it to the other data type. the **second** argument takes a lists. It will apply this function to every element of the lists, and return a new lists.\r\n\r\nExample: I want to twice the number in the lists, we can write down\r\n\r\n```Haskell\r\n\r\n    Prelude> let let = [1..]\r\n    Prelude> let lst2 = map (\\x-> x * 2) lst\r\n    Prelude> take 4 lst2\r\n    [2,4,6,8]\r\n    Prelude> take 4 lst\r\n    [1,2,3,4]\r\n\r\n```\r\nThis small piece code demonstrates that how map works in Haskell.\r\n\r\nMap function is extremely useful when you want to create a key-value pair. For example, we take the original set **lst** as the key, and the value is the elements in **lst2**, so how do we do that?\r\n\r\n```Haskell\r\n\r\n    Prelude> let lst3 = map (\\x -> (x, x * 2)) lst\r\n    Prelude> take 4 lst3\r\n    [(1,2),(2,4),(3,6),(4,8)]\r\n    Prelude> \r\n\r\n```\r\nSee, now it is actually a key-value pair.\r\n\r\nAnother useful technique in functional world is **reduce**: somehow combines the elements in the lists and formulate the results.\r\n\r\nImagine that we want to calculate the appearance of each character in a world. We first map each character into a key-value pair, with value of 1 for each character, and then we combine the one with the same key.\r\n\r\n```Haskell\r\n\r\n    import Data.List\r\n\r\n    -- Normal Reduce Function\r\n    rd :: (a -> a -> a) -> [a] -> a\r\n    rd _ [] = error \"the list to be reduced should not be empty\"\r\n    rd f (x:xs) = rdHelper x xs\r\n        where rdHelper a [] = a\r\n              rdHelper a (y:ys) = rdHelper (f a y) ys\r\n\r\n    -- Sort by the key\r\n    sortByKey :: Ord k => [(k, v)] -> [(k, v)]\r\n    sortByKey lst = sortBy keyCmp lst\r\n        where keyCmp x y = compare (fst x) (fst y)\r\n\r\n    -- Reduce by Key\r\n    rdByKey :: Eq k => (v -> v -> v) -> [(k,v)] -> [(k,v)]\r\n    rdByKey _ [] = []\r\n    rdByKey _ (x:[]) = [x]\r\n    rdByKey f (x:y:xs) = if sameKey x y then rdByKey f ([(combinePair f x y)] ++ xs) else ([x] ++ (rdByKey f ([y] ++ xs)))\r\n        where combinePair f x y = (fst x, f (snd x) (snd y)) \r\n              sameKey (k1, v1) (k2, v2) = k1 == k2\r\n\r\n```\r\nI write this short reduce by key function help you create this functionality.\r\nTo count the char, we simply do\r\n\r\n```Haskell\r\n\r\n    *Main> let s = \"asdfasdfasqewr\"\r\n    *Main> let countchar = rdByKey (+) . sortByKey . map (\\x -> (x, 1))\r\n    *Main> countchar s\r\n    [('a',3),('d',2),('e',1),('f',2),('q',1),('r',1),('s',3),('w',1)]\r\n\r\n```\r\nOnly three lines of code.", "title": "Learn Computer Science From Scratch -- Map and Reduce in Function world"}, "Learn_Computer_Science_From_Scratch_-_Boyer-Moore_Algorithm": {"date": "2018-08-05 21:13", "md": "There are a lot of efficient string search (pattern matching) algorithm in the world, and Boyer-Moore algorithm is one of those algorithm commonly used in  finding long pattern in a longer string.\n\nProbably, the most simple algorithm is called Naive Pattern Searching Algorithm:\n\n1.  Match every character in the pattern and the corresponding position in the string. If all the characters match, return the resulting position.\n2.  If there is a mismatch, simply move the pattern by 1 character.\n3.  Repeat the process until the pattern hit the end of the algorithm.\nHowever, the algorithm is not efficient. In most of the case, the algorithm takes \u0398(nm).\n\nIn Boyer-Moore algorithm, instead of comparing from the left to the right, it compares from the right to the left.\n\nThen two rules apply when a mismatch happens:\n\n*   Bad character rule:\nIf a mismatch happens on pattern position **_p_** and pattern's first character is at position**_ i _**, the mismatched character is at **_(p + i)_**. If the mismatched character appears on the left side of mismatched character, move the pattern so that the character are in the same position, and repeat the process of matching. If not, simply move the entire pattern by the length of pattern.\n\n![](/img/Screen-Shot-2017-09-17-at-7.13.58-PM-300x138.png)\n\n*   Good suffix rule: If a mismatch happens, some continuous behind the mismatch (called suffix) appears in front of mismatch position (prefix), move so that the prefix and suffix part meet.\n![](/img/Screen-Shot-2017-09-17-at-7.37.48-PM-300x119.png)\n\nBoyer-Moore Algorithm is a simple combination of these two rules, and each step will move at least 1 step. If one rule skip more step, apply the rule.", "title": "Learn Computer Science From Scratch - Boyer-Moore Algorithm"}, "Hilbert_10_meets_Isabelle": {"date": "2018-08-05 21:13", "md": "The study of Diophantine equation has always been people's interest. Although such equations are in a very primitive form, finding its solution seems less intuitive, and people, for centuries, strives to formulate the general solution, and no one has yet successfully achieve such a task.\n\nIf one can find such general solution, or algorithm to find the solution, many mathematical problems will be solved, including Goldbach conjecture and some other twin prime problems.\n\nDavid Hilbert, one of the most famous German mathematician in 20th century, raised a question about the general algorithm to find solution to Diophantine equation.\n\nYuri Matiyasevich, in the late 20th century, formulate the solution for Hilbert 10th problem. The result shows that such algorithm cannot exists.\n\nThe main proof basically discusses about the close relation between recursively enumerable set and exponential Diophantine equation.\n\nIn 2017, Yuri Matiyasevich visited Jacobs University Bremen and initiate a further research into Hilbert 10th problem, and I am grateful I could be part of the team.\n\nWith the booming of information technology, automatic theorem proving software greatly simplified the task of mathematical research, and we decided to use Isabelle, a theorem prover designed in Cambridge to support our project.\n\nThis blog post denote the starting of this project, and I will write more about Hilbert 10th problem in detail in the next few post.", "title": "Hilbert 10 meets Isabelle"}, "Learn_Computer_Science_From_Scratch_-_Recursive_Functions": {"date": "2018-08-05 21:13", "md": "Recursive functions are amazing tools for programmers to do iteration without using a traditional for-loop. It is also the only tool in function programming language to do iteration.\n\nIn Haskell, recursive functions look like this:\n\n```Haskell\n\n    sum_up x\n      ' x == 0 = 0\n      ' otherwise = x + sum_up (x - 1)\n\n```\nThis is a recursive functions that returns the sum of natural numbers from 0 to n in just three line of code. Amazing right?\n\nBut, sometimes, recursive functions are hard to understand, so we need to formulate a way to comprehend the algorithm and check if the algorithm is working.\n\n**To prove a recursive algorithm is working, we need to prove three idea of this algorithm**:\n\n*   **Initialization**: Checking the boundary of inputs, make sure the variable is properly initialized.\n*   **Maintenance**: the assumption for the algorithm holds before and after every recursive calls\n*   **Termination**: we do not want a recursive algorithm that never terminates( infinite recursive calls will consumes large amount of memory.)\nIf you read through my code for sum up again, you will see that it is not properly initialized. What if I gave a negative number as an input? We need to code defensively to make a more robust program. (Such idea is called defensive programming)\n\nTo understand better for recursive algorithm, I will give you a example of Fibonacci function, which calculates the nth number in a Fibonacci sequence.\n\n```Haskell\n\n    fib :: Integer -> Integer\n    fib x\n      ' x < 1 = error \"n should be greater than 0\" \n      ' x == 1 = 1\n      ' x == 2 = 2\n      ' otherwise = fib (x - 1) + fib (x - 2)\n\n```\n**Note** that this is just a simple version, and it is not the optimal algorithm for calculating Fibonacci number.(the time complexity is exponential, and there is a solution to reduce this algorithm to linear time, think about it.)", "title": "Learn Computer Science From Scratch - Recursive Functions"}, "Learn_Computer_Science_From_Scratch_-_Complexity_and_Correctness": {"date": "2018-08-05 21:13", "md": "## Complexity\n\n> Complexity is an abstract measurer of computational effort and memory usage.\nThis simple definition tells us that the complexity of a algorithm can be break into two part:\n\n*   **Time complexity**\n*   **Space complexity**\nTo analyse the time complexity of a algorithm, we usually analyse the order of growth:\n\n1.  Constant: using the same amount of time no matter the inputs.\n2.  Linear: the time grows linearly with the size of the input.\n3.  Logarithm\n4.  Linearithmic( or log-linear)\n5.  Quadratic: Might be a little annoying starting here.\n6.  Polynomial\n7.  Exponential: We don't want it, it is not scalable at all.\nA good algorithm should be scalable according to the definition of the algorithm.\n\nThe space complexity is similar, and we also use order of growth to analyse it.\n\n## Correctness\n\nAs a computer scientist, we often want to write a correct algorithms, and correctness is a important part.\n\nFirst, I should give you the definition of **partial correctness.**\n> An algorithm in a state that satisfies a precondition P is partially correct with respect to P and Q if results produced by the algorithm satisfy the postcondition Q.\nNote that a algorithm is partially correct does not mean that it will give you a correct result. It actually means that if the algorithm produced a result, it will be correct, which implies that this algorithm may not give you a result.\n\nNow we can move forward to** total correctness.** Total correct algorithm is a partially correct algorithm that always gives a result.", "title": "Learn Computer Science From Scratch - Complexity and Correctness"}, "Learn_Computer_Science_from_Scratch_--_Recursive_Function_Revisted": {"date": "2018-08-05 21:13", "md": "In a previous blog post, I mentioned a little bit of recursive function in Haskell, and about how they works.\n\nToday we are going deeper into recursive functions, especially in Haskell.\n\nA typical property of problems solvable by recursion is divide-and-conquer -- first divide the problem into its subproblems, then merge the result in a certain way.\n\nTo be more specific, we apply three steps at each level of recursion:\n\n*   > **Divide** the problem into a number of subproblems that are smaller instances of the same problem.\n\n*   > **Conquer** the subproblems by solving them recursively. If the subproblem sizes are small enough, however, just solve the subproblems in a straightforward manner.\n\n*   > **Combine** the solutions to the subproblems into the solution for the original problem\nLast time, I gave a example of recursive function in my blog -- Fibonacci function, today I will take it apart analyse it.\n\n```Haskell\n\n    fib :: Integer -> Integer\n    fib x\n      ' x < 1 = error \"n should be greater than 0\" \n      ' x == 1 = 1\n      ' x == 2 = 2\n      ' otherwise = fib (x - 1) + fib (x - 2)\n\n```\n\nHow do we **divide** the problem of finding the nth Fibonacci number?\n\nWe know that, by definition, a Fibonacci number is the sum of the previous two Fibonacci number. we break the problem into the subproblem, finding its previous two Fibonacci number.\n\nHow to **conquer** the problem?\n\nIf the subproblem is simple enough, it is straight forward, we have already know the 1st and 2nd Fibonacci number, just simply plug it in. (Of course, you can put more cases in the code.)\n\nIf it is not that simple, well, continue by solving its subproblem, of course.\n\nHow do we **combine** the solution?\n\nThis one is straight forward. Once we obtained the previous two Fibonacci number, we just summing them up and return the result.\n\nHowever, if I tell you that there are some problem in the code above, it might be kind of hard to see.\n\nIn our previous Fibonacci number function, Fibonacci number function is called multiple times on a single argument.\n\nFor example, if we want to calculate the 5th Fibonacci number -- _fib 5_, we will calculate  _fib 4_  and  _fib 3_. However, in the calculation of _fib 4_, we calculated _fib 2_ and again _fib 3_. Clearly, fib 3 is been calculated multiple times.\n\nTo generalize, the algorithm given above has a cubic order of growth -- with the size of input growing linearly, the time complexity, or the running time of the program, grows as it is a cubic function.\n\nTo solve this problem in the algorithm, we can either use memorization or introduce a new helper function. I will discuss it in the next blog post.", "title": "Learn Computer Science from Scratch -- Recursive Function Revisted"}}